<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Visual Assistant</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: Arial, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
            color: white;
        }

        .container {
            max-width: 500px;
            width: 100%;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.2);
            text-align: center;
        }

        h1 {
            font-size: 2.5rem;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }

        .subtitle {
            font-size: 1.2rem;
            margin-bottom: 30px;
            opacity: 0.9;
        }

        .camera-section {
            margin-bottom: 30px;
        }

        #video {
            width: 100%;
            max-width: 400px;
            height: 300px;
            border-radius: 15px;
            border: 3px solid rgba(255, 255, 255, 0.3);
            background: #000;
            margin-bottom: 20px;
            object-fit: cover;
        }

        .controls {
            display: flex;
            flex-direction: column;
            gap: 15px;
            margin-bottom: 30px;
        }

        .btn {
            padding: 15px 30px;
            font-size: 1.2rem;
            font-weight: bold;
            border: none;
            border-radius: 50px;
            cursor: pointer;
            transition: all 0.3s ease;
            color: white;
            text-transform: uppercase;
            letter-spacing: 1px;
        }

        .btn-primary {
            background: linear-gradient(45deg, #ff6b6b, #ee5a24);
            box-shadow: 0 10px 20px rgba(238, 90, 36, 0.3);
        }

        .btn-primary:hover {
            transform: translateY(-3px);
            box-shadow: 0 15px 30px rgba(238, 90, 36, 0.4);
        }

        .btn-secondary {
            background: linear-gradient(45deg, #48cae4, #0077b6);
            box-shadow: 0 10px 20px rgba(0, 119, 182, 0.3);
        }

        .btn-secondary:hover {
            transform: translateY(-3px);
            box-shadow: 0 15px 30px rgba(0, 119, 182, 0.4);
        }

        .btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none !important;
        }

        .status {
            background: rgba(255, 255, 255, 0.1);
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
            min-height: 60px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.1rem;
        }

        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid rgba(255, 255, 255, 0.3);
            border-radius: 50%;
            border-top-color: #fff;
            animation: spin 1s ease-in-out infinite;
            margin-right: 10px;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        .description-box {
            background: rgba(255, 255, 255, 0.15);
            padding: 20px;
            border-radius: 15px;
            margin-top: 20px;
            text-align: left;
            line-height: 1.6;
            font-size: 1.1rem;
            min-height: 100px;
            display: flex;
            align-items: center;
        }

        .setup-instructions {
            background: rgba(255, 193, 7, 0.2);
            border: 2px solid rgba(255, 193, 7, 0.5);
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
            text-align: left;
        }

        .setup-instructions h3 {
            margin-bottom: 10px;
            color: #ffc107;
        }

        .setup-instructions ol {
            margin-left: 20px;
        }

        .setup-instructions li {
            margin-bottom: 5px;
        }

        @media (max-width: 600px) {
            .container {
                padding: 20px;
            }
            
            h1 {
                font-size: 2rem;
            }
            
            .btn {
                padding: 12px 25px;
                font-size: 1rem;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üëÅÔ∏è AI Visual Assistant</h1>
        <p class="subtitle">Real-time scene description for accessibility</p>

        <div class="setup-instructions">
            <h3>‚öôÔ∏è Quick Setup Required:</h3>
            <ol>
                <li>Get <strong>Google Vision API key</strong> from Google Cloud Console</li>
                <li>Get <strong>ElevenLabs API key</strong> from elevenlabs.io</li>
                <li>Replace the API keys in the JavaScript section below</li>
                <li>Allow camera permissions when prompted</li>
            </ol>
        </div>

        <div class="camera-section">
            <video id="video" autoplay muted playsinline></video>
        </div>

        <div class="controls">
            <button id="startCamera" class="btn btn-primary">üìπ Start Camera</button>
            <button id="captureBtn" class="btn btn-secondary" disabled>üì∏ Describe Scene</button>
            <button id="readTextBtn" class="btn btn-secondary" disabled>üìñ Read Text</button>
        </div>

        <div class="status" id="status">
            Click "Start Camera" to begin
        </div>

        <div class="description-box" id="description">
            Descriptions will appear here...
        </div>
    </div>

    <script>
        // ‚ö†Ô∏è REPLACE THESE WITH YOUR ACTUAL API KEYS
        const GOOGLE_VISION_API_KEY = 'AIzaSyDCy6bkrz6CUYbwZGCoWacEaKEvM-U4ttU';
        const ELEVENLABS_API_KEY = 'sk_3b44b143ef48aae7066bfb7753eee96885329bb3eeb91243';
        const ELEVENLABS_VOICE_ID = 'pNInz6obpgDQGcFmaJgB'; // Default voice, you can change this

        class AIVisualAssistant {
            constructor() {
                this.video = document.getElementById('video');
                this.canvas = document.createElement('canvas');
                this.ctx = this.canvas.getContext('2d');
                this.stream = null;
                
                this.setupEventListeners();
                this.checkAPIKeys();
            }

            checkAPIKeys() {
                if (GOOGLE_VISION_API_KEY.includes('YOUR_') || ELEVENLABS_API_KEY.includes('YOUR_')) {
                    this.updateStatus('‚ö†Ô∏è Please add your API keys to get started');
                    return false;
                }
                return true;
            }

            setupEventListeners() {
                document.getElementById('startCamera').addEventListener('click', () => this.startCamera());
                document.getElementById('captureBtn').addEventListener('click', () => this.captureAndDescribe());
                document.getElementById('readTextBtn').addEventListener('click', () => this.captureAndReadText());
                
                // Voice commands (if supported)
                if ('webkitSpeechRecognition' in window) {
                    this.setupVoiceCommands();
                }
            }

            async startCamera() {
                try {
                    this.updateStatus('üìπ Starting camera...');
                    this.stream = await navigator.mediaDevices.getUserMedia({ 
                        video: { 
                            width: { ideal: 1280 },
                            height: { ideal: 720 },
                            facingMode: 'environment' // Use back camera on mobile
                        } 
                    });
                    
                    this.video.srcObject = this.stream;
                    this.updateStatus('‚úÖ Camera ready! Point at objects and click describe.');
                    
                    document.getElementById('startCamera').disabled = true;
                    document.getElementById('captureBtn').disabled = false;
                    document.getElementById('readTextBtn').disabled = false;
                    
                } catch (error) {
                    console.error('Camera error:', error);
                    this.updateStatus('‚ùå Camera access denied. Please allow camera permissions.');
                }
            }

            captureImage() {
                this.canvas.width = this.video.videoWidth;
                this.canvas.height = this.video.videoHeight;
                this.ctx.drawImage(this.video, 0, 0);
                return this.canvas.toDataURL('image/jpeg', 0.8).split(',')[1]; // Remove data:image/jpeg;base64,
            }

            async captureAndDescribe() {
                if (!this.checkAPIKeys()) return;
                
                try {
                    this.updateStatus('üîç Analyzing scene...', true);
                    const imageBase64 = this.captureImage();
                    
                    const response = await fetch(`https://vision.googleapis.com/v1/images:annotate?key=${GOOGLE_VISION_API_KEY}`, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            requests: [{
                                image: {
                                    content: imageBase64
                                },
                                features: [
                                    { type: 'LABEL_DETECTION', maxResults: 10 },
                                    { type: 'OBJECT_LOCALIZATION', maxResults: 10 },
                                    { type: 'TEXT_DETECTION', maxResults: 5 }
                                ]
                            }]
                        })
                    });

                    const data = await response.json();
                    const description = this.generateSceneDescription(data);
                    
                    document.getElementById('description').textContent = description;
                    await this.speakText(description);
                    this.updateStatus('‚úÖ Scene described successfully!');
                    
                } catch (error) {
                    console.error('Vision API error:', error);
                    this.updateStatus('‚ùå Error analyzing image. Check your API key.');
                }
            }

            async captureAndReadText() {
                if (!this.checkAPIKeys()) return;
                
                try {
                    this.updateStatus('üìñ Reading text...', true);
                    const imageBase64 = this.captureImage();
                    
                    const response = await fetch(`https://vision.googleapis.com/v1/images:annotate?key=${GOOGLE_VISION_API_KEY}`, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            requests: [{
                                image: {
                                    content: imageBase64
                                },
                                features: [
                                    { type: 'TEXT_DETECTION', maxResults: 1 }
                                ]
                            }]
                        })
                    });

                    const data = await response.json();
                    const text = this.extractText(data);
                    
                    if (text) {
                        document.getElementById('description').textContent = `Text found: "${text}"`;
                        await this.speakText(text);
                        this.updateStatus('‚úÖ Text read successfully!');
                    } else {
                        const noTextMsg = "No readable text found in the image.";
                        document.getElementById('description').textContent = noTextMsg;
                        await this.speakText(noTextMsg);
                        this.updateStatus('‚ÑπÔ∏è No text detected in image.');
                    }
                    
                } catch (error) {
                    console.error('Text reading error:', error);
                    this.updateStatus('‚ùå Error reading text. Check your API key.');
                }
            }

            generateSceneDescription(visionData) {
                const responses = visionData.responses[0];
                let description = "I can see ";
                
                // Get objects and labels
                const objects = responses.localizedObjectAnnotations || [];
                const labels = responses.labelAnnotations || [];
                
                if (objects.length > 0) {
                    const objectNames = objects.map(obj => obj.name.toLowerCase()).slice(0, 5);
                    description += objectNames.join(', ');
                } else if (labels.length > 0) {
                    const labelNames = labels.map(label => label.description.toLowerCase()).slice(0, 5);
                    description += labelNames.join(', ');
                } else {
                    description = "I can see the scene, but I'm having trouble identifying specific objects. Try moving closer or adjusting the lighting.";
                }
                
                // Add text if found
                const textAnnotations = responses.textAnnotations || [];
                if (textAnnotations.length > 0) {
                    description += `. I also notice some text that says: "${textAnnotations[0].description.substring(0, 100)}"`;
                }
                
                return description + ".";
            }

            extractText(visionData) {
                const responses = visionData.responses[0];
                const textAnnotations = responses.textAnnotations || [];
                
                if (textAnnotations.length > 0) {
                    return textAnnotations[0].description.trim();
                }
                return null;
            }

            async speakText(text) {
                if (!ELEVENLABS_API_KEY.includes('YOUR_')) {
                    try {
                        const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${ELEVENLABS_VOICE_ID}`, {
                            method: 'POST',
                            headers: {
                                'Accept': 'audio/mpeg',
                                'Content-Type': 'application/json',
                                'xi-api-key': ELEVENLABS_API_KEY
                            },
                            body: JSON.stringify({
                                text: text,
                                model_id: 'eleven_monolingual_v1',
                                voice_settings: {
                                    stability: 0.5,
                                    similarity_boost: 0.5
                                }
                            })
                        });

                        if (response.ok) {
                            const audioBlob = await response.blob();
                            const audioUrl = URL.createObjectURL(audioBlob);
                            const audio = new Audio(audioUrl);
                            audio.play();
                        }
                    } catch (error) {
                        console.error('ElevenLabs TTS error:', error);
                        // Fallback to browser TTS
                        this.fallbackTTS(text);
                    }
                } else {
                    // Use browser TTS as fallback
                    this.fallbackTTS(text);
                }
            }

            fallbackTTS(text) {
                if ('speechSynthesis' in window) {
                    const utterance = new SpeechSynthesisUtterance(text);
                    utterance.rate = 0.8;
                    utterance.pitch = 1;
                    speechSynthesis.speak(utterance);
                }
            }

            setupVoiceCommands() {
                const recognition = new webkitSpeechRecognition();
                recognition.continuous = true;
                recognition.interimResults = false;
                
                recognition.onresult = (event) => {
                    const command = event.results[event.results.length - 1][0].transcript.toLowerCase();
                    
                    if (command.includes('describe') || command.includes('scene')) {
                        this.captureAndDescribe();
                    } else if (command.includes('read') || command.includes('text')) {
                        this.captureAndReadText();
                    }
                };
                
                recognition.start();
            }

            updateStatus(message, loading = false) {
                const statusEl = document.getElementById('status');
                statusEl.innerHTML = loading ? `<div class="loading"></div>${message}` : message;
            }
        }

        // Initialize AI Visual Assistant
        document.addEventListener('DOMContentLoaded', () => {
            new AIVisualAssistant();
        });
    </script>
</body>
</html>